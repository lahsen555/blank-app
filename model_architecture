digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	138280652518224 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	138281255522784 [label=AddmmBackward0]
	138280657287056 -> 138281255522784
	138280784723216 [label="fc.bias
 (1000)" fillcolor=lightblue]
	138280784723216 -> 138280657287056
	138280657287056 [label=AccumulateGrad]
	138280657284272 -> 138281255522784
	138280657284272 [label=ViewBackward0]
	138280657287248 -> 138280657284272
	138280657287248 [label=MeanBackward1]
	138280657283168 -> 138280657287248
	138280657283168 [label=ReluBackward0]
	138280657275632 -> 138280657283168
	138280657275632 [label=AddBackward0]
	138280657284656 -> 138280657275632
	138280657284656 [label=NativeBatchNormBackward0]
	138280657279232 -> 138280657284656
	138280657279232 [label=ConvolutionBackward0]
	138280657282352 -> 138280657279232
	138280657282352 [label=ReluBackward0]
	138280657288256 -> 138280657282352
	138280657288256 [label=NativeBatchNormBackward0]
	138280657284608 -> 138280657288256
	138280657284608 [label=ConvolutionBackward0]
	138280657285088 -> 138280657284608
	138280657285088 [label=ReluBackward0]
	138280657275872 -> 138280657285088
	138280657275872 [label=AddBackward0]
	138280657274864 -> 138280657275872
	138280657274864 [label=NativeBatchNormBackward0]
	138280657288496 -> 138280657274864
	138280657288496 [label=ConvolutionBackward0]
	138280657282304 -> 138280657288496
	138280657282304 [label=ReluBackward0]
	138280657280768 -> 138280657282304
	138280657280768 [label=NativeBatchNormBackward0]
	138280657276208 -> 138280657280768
	138280657276208 [label=ConvolutionBackward0]
	138280657276064 -> 138280657276208
	138280657276064 [label=ReluBackward0]
	138280657280384 -> 138280657276064
	138280657280384 [label=AddBackward0]
	138280657288592 -> 138280657280384
	138280657288592 [label=NativeBatchNormBackward0]
	138280657288448 -> 138280657288592
	138280657288448 [label=ConvolutionBackward0]
	138280657280480 -> 138280657288448
	138280657280480 [label=ReluBackward0]
	138280657287776 -> 138280657280480
	138280657287776 [label=NativeBatchNormBackward0]
	138280657288688 -> 138280657287776
	138280657288688 [label=ConvolutionBackward0]
	138280657273712 -> 138280657288688
	138280657273712 [label=ReluBackward0]
	138280657273184 -> 138280657273712
	138280657273184 [label=AddBackward0]
	138280657288016 -> 138280657273184
	138280657288016 [label=NativeBatchNormBackward0]
	138280657280000 -> 138280657288016
	138280657280000 [label=ConvolutionBackward0]
	138280657287488 -> 138280657280000
	138280657287488 [label=ReluBackward0]
	138280657287584 -> 138280657287488
	138280657287584 [label=NativeBatchNormBackward0]
	138280657287104 -> 138280657287584
	138280657287104 [label=ConvolutionBackward0]
	138280657286144 -> 138280657287104
	138280657286144 [label=ReluBackward0]
	138280657286432 -> 138280657286144
	138280657286432 [label=AddBackward0]
	138280657285904 -> 138280657286432
	138280657285904 [label=NativeBatchNormBackward0]
	138280657285136 -> 138280657285904
	138280657285136 [label=ConvolutionBackward0]
	138280657285520 -> 138280657285136
	138280657285520 [label=ReluBackward0]
	138280657284320 -> 138280657285520
	138280657284320 [label=NativeBatchNormBackward0]
	138280657284176 -> 138280657284320
	138280657284176 [label=ConvolutionBackward0]
	138280657286528 -> 138280657284176
	138280657286528 [label=ReluBackward0]
	138280657283792 -> 138280657286528
	138280657283792 [label=AddBackward0]
	138280657283600 -> 138280657283792
	138280657283600 [label=NativeBatchNormBackward0]
	138280657283888 -> 138280657283600
	138280657283888 [label=ConvolutionBackward0]
	138280657274192 -> 138280657283888
	138280657274192 [label=ReluBackward0]
	138280657282544 -> 138280657274192
	138280657282544 [label=NativeBatchNormBackward0]
	138280657282400 -> 138280657282544
	138280657282400 [label=ConvolutionBackward0]
	138280657281776 -> 138280657282400
	138280657281776 [label=ReluBackward0]
	138280657281584 -> 138280657281776
	138280657281584 [label=AddBackward0]
	138280657281200 -> 138280657281584
	138280657281200 [label=NativeBatchNormBackward0]
	138280657279040 -> 138280657281200
	138280657279040 [label=ConvolutionBackward0]
	138280657279664 -> 138280657279040
	138280657279664 [label=ReluBackward0]
	138280657280624 -> 138280657279664
	138280657280624 [label=NativeBatchNormBackward0]
	138280657279808 -> 138280657280624
	138280657279808 [label=ConvolutionBackward0]
	138280657287920 -> 138280657279808
	138280657287920 [label=ReluBackward0]
	138280657284704 -> 138280657287920
	138280657284704 [label=AddBackward0]
	138280657282784 -> 138280657284704
	138280657282784 [label=NativeBatchNormBackward0]
	138280657284896 -> 138280657282784
	138280657284896 [label=ConvolutionBackward0]
	138280657281056 -> 138280657284896
	138280657281056 [label=ReluBackward0]
	138280657288784 -> 138280657281056
	138280657288784 [label=NativeBatchNormBackward0]
	138280657284080 -> 138280657288784
	138280657284080 [label=ConvolutionBackward0]
	138280657283840 -> 138280657284080
	138280657283840 [label=MaxPool2DWithIndicesBackward0]
	138280657278176 -> 138280657283840
	138280657278176 [label=ReluBackward0]
	138280657277312 -> 138280657278176
	138280657277312 [label=NativeBatchNormBackward0]
	138280657277168 -> 138280657277312
	138280657277168 [label=ConvolutionBackward0]
	138280657277696 -> 138280657277168
	138280784711600 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	138280784711600 -> 138280657277696
	138280657277696 [label=AccumulateGrad]
	138280657277600 -> 138280657277312
	138280784711696 [label="bn1.weight
 (64)" fillcolor=lightblue]
	138280784711696 -> 138280657277600
	138280657277600 [label=AccumulateGrad]
	138280657285616 -> 138280657277312
	138280784711792 [label="bn1.bias
 (64)" fillcolor=lightblue]
	138280784711792 -> 138280657285616
	138280657285616 [label=AccumulateGrad]
	138280657287824 -> 138280657284080
	138280784712176 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784712176 -> 138280657287824
	138280657287824 [label=AccumulateGrad]
	138280657279328 -> 138280657288784
	138280784712272 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	138280784712272 -> 138280657279328
	138280657279328 [label=AccumulateGrad]
	138280657285040 -> 138280657288784
	138280784712368 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	138280784712368 -> 138280657285040
	138280657285040 [label=AccumulateGrad]
	138280657287728 -> 138280657284896
	138280784712752 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784712752 -> 138280657287728
	138280657287728 [label=AccumulateGrad]
	138280657282208 -> 138280657282784
	138280784712848 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	138280784712848 -> 138280657282208
	138280657282208 [label=AccumulateGrad]
	138280657281344 -> 138280657282784
	138280784712944 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	138280784712944 -> 138280657281344
	138280657281344 [label=AccumulateGrad]
	138280657283840 -> 138280657284704
	138280657281152 -> 138280657279808
	138280784713328 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784713328 -> 138280657281152
	138280657281152 [label=AccumulateGrad]
	138280657282064 -> 138280657280624
	138280784713424 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	138280784713424 -> 138280657282064
	138280657282064 [label=AccumulateGrad]
	138280657279424 -> 138280657280624
	138280784713520 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	138280784713520 -> 138280657279424
	138280657279424 [label=AccumulateGrad]
	138280657279280 -> 138280657279040
	138280784713904 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784713904 -> 138280657279280
	138280657279280 [label=AccumulateGrad]
	138280657280240 -> 138280657281200
	138280784714000 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	138280784714000 -> 138280657280240
	138280657280240 [label=AccumulateGrad]
	138280657281248 -> 138280657281200
	138280784714096 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	138280784714096 -> 138280657281248
	138280657281248 [label=AccumulateGrad]
	138280657287920 -> 138280657281584
	138280657273520 -> 138280657282400
	138280784715056 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	138280784715056 -> 138280657273520
	138280657273520 [label=AccumulateGrad]
	138280657274576 -> 138280657282544
	138280784715152 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	138280784715152 -> 138280657274576
	138280657274576 [label=AccumulateGrad]
	138280657282448 -> 138280657282544
	138280784715248 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	138280784715248 -> 138280657282448
	138280657282448 [label=AccumulateGrad]
	138280657282832 -> 138280657283888
	138280784715632 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784715632 -> 138280657282832
	138280657282832 [label=AccumulateGrad]
	138280657283360 -> 138280657283600
	138280784715728 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	138280784715728 -> 138280657283360
	138280657283360 [label=AccumulateGrad]
	138280657283504 -> 138280657283600
	138280784715824 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	138280784715824 -> 138280657283504
	138280657283504 [label=AccumulateGrad]
	138280657283312 -> 138280657283792
	138280657283312 [label=NativeBatchNormBackward0]
	138280657281824 -> 138280657283312
	138280657281824 [label=ConvolutionBackward0]
	138280657281776 -> 138280657281824
	138280657281728 -> 138280657281824
	138280784714480 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	138280784714480 -> 138280657281728
	138280657281728 [label=AccumulateGrad]
	138280657283072 -> 138280657283312
	138280784714576 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	138280784714576 -> 138280657283072
	138280657283072 [label=AccumulateGrad]
	138280657282928 -> 138280657283312
	138280784714672 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	138280784714672 -> 138280657282928
	138280657282928 [label=AccumulateGrad]
	138280657283984 -> 138280657284176
	138280784716208 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784716208 -> 138280657283984
	138280657283984 [label=AccumulateGrad]
	138280657284416 -> 138280657284320
	138280784716304 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	138280784716304 -> 138280657284416
	138280657284416 [label=AccumulateGrad]
	138280657285184 -> 138280657284320
	138280784716400 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	138280784716400 -> 138280657285184
	138280657285184 [label=AccumulateGrad]
	138280657276832 -> 138280657285136
	138280784716784 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784716784 -> 138280657276832
	138280657276832 [label=AccumulateGrad]
	138280657285664 -> 138280657285904
	138280784716880 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	138280784716880 -> 138280657285664
	138280657285664 [label=AccumulateGrad]
	138280657285568 -> 138280657285904
	138280784716976 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	138280784716976 -> 138280657285568
	138280657285568 [label=AccumulateGrad]
	138280657286528 -> 138280657286432
	138280657286336 -> 138280657287104
	138280784717936 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	138280784717936 -> 138280657286336
	138280657286336 [label=AccumulateGrad]
	138280657287008 -> 138280657287584
	138280784717840 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	138280784717840 -> 138280657287008
	138280657287008 [label=AccumulateGrad]
	138280657278944 -> 138280657287584
	138280784718128 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	138280784718128 -> 138280657278944
	138280657278944 [label=AccumulateGrad]
	138280657279952 -> 138280657280000
	138280784718512 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784718512 -> 138280657279952
	138280657279952 [label=AccumulateGrad]
	138280657288400 -> 138280657288016
	138280784718608 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	138280784718608 -> 138280657288400
	138280657288400 [label=AccumulateGrad]
	138280657288208 -> 138280657288016
	138280784718704 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	138280784718704 -> 138280657288208
	138280657288208 [label=AccumulateGrad]
	138280657281104 -> 138280657273184
	138280657281104 [label=NativeBatchNormBackward0]
	138280657286864 -> 138280657281104
	138280657286864 [label=ConvolutionBackward0]
	138280657286144 -> 138280657286864
	138280657286624 -> 138280657286864
	138280784717360 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	138280784717360 -> 138280657286624
	138280657286624 [label=AccumulateGrad]
	138280657279856 -> 138280657281104
	138280784717456 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	138280784717456 -> 138280657279856
	138280657279856 [label=AccumulateGrad]
	138280657280192 -> 138280657281104
	138280784717552 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	138280784717552 -> 138280657280192
	138280657280192 [label=AccumulateGrad]
	138280657272992 -> 138280657288688
	138280784719088 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784719088 -> 138280657272992
	138280657272992 [label=AccumulateGrad]
	138280657281008 -> 138280657287776
	138280784719184 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	138280784719184 -> 138280657281008
	138280657281008 [label=AccumulateGrad]
	138280657286720 -> 138280657287776
	138280784719280 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	138280784719280 -> 138280657286720
	138280657286720 [label=AccumulateGrad]
	138280657280672 -> 138280657288448
	138280784719664 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784719664 -> 138280657280672
	138280657280672 [label=AccumulateGrad]
	138280657288304 -> 138280657288592
	138280784719760 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	138280784719760 -> 138280657288304
	138280657288304 [label=AccumulateGrad]
	138280657289072 -> 138280657288592
	138280784719856 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	138280784719856 -> 138280657289072
	138280657289072 [label=AccumulateGrad]
	138280657273712 -> 138280657280384
	138280657287296 -> 138280657276208
	138280784720816 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	138280784720816 -> 138280657287296
	138280657287296 [label=AccumulateGrad]
	138280657275680 -> 138280657280768
	138280784720912 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	138280784720912 -> 138280657275680
	138280657275680 [label=AccumulateGrad]
	138280657282736 -> 138280657280768
	138280784721008 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	138280784721008 -> 138280657282736
	138280657282736 [label=AccumulateGrad]
	138280657278800 -> 138280657288496
	138280784721392 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784721392 -> 138280657278800
	138280657278800 [label=AccumulateGrad]
	138280657273568 -> 138280657274864
	138280784721488 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	138280784721488 -> 138280657273568
	138280657273568 [label=AccumulateGrad]
	138280657273616 -> 138280657274864
	138280784721584 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	138280784721584 -> 138280657273616
	138280657273616 [label=AccumulateGrad]
	138280657274336 -> 138280657275872
	138280657274336 [label=NativeBatchNormBackward0]
	138280657278656 -> 138280657274336
	138280657278656 [label=ConvolutionBackward0]
	138280657276064 -> 138280657278656
	138280657284464 -> 138280657278656
	138280784720240 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	138280784720240 -> 138280657284464
	138280657284464 [label=AccumulateGrad]
	138280657285376 -> 138280657274336
	138280784720336 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	138280784720336 -> 138280657285376
	138280657285376 [label=AccumulateGrad]
	138280657285856 -> 138280657274336
	138280784720432 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	138280784720432 -> 138280657285856
	138280657285856 [label=AccumulateGrad]
	138280657276736 -> 138280657284608
	138280784721968 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784721968 -> 138280657276736
	138280657276736 [label=AccumulateGrad]
	138280657283696 -> 138280657288256
	138280784722064 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	138280784722064 -> 138280657283696
	138280657283696 [label=AccumulateGrad]
	138280657280432 -> 138280657288256
	138280784722160 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	138280784722160 -> 138280657280432
	138280657280432 [label=AccumulateGrad]
	138280657280144 -> 138280657279232
	138280784722544 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784722544 -> 138280657280144
	138280657280144 [label=AccumulateGrad]
	138280657281968 -> 138280657284656
	138280784722640 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	138280784722640 -> 138280657281968
	138280657281968 [label=AccumulateGrad]
	138280657283120 -> 138280657284656
	138280784722736 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	138280784722736 -> 138280657283120
	138280657283120 [label=AccumulateGrad]
	138280657285088 -> 138280657275632
	138280657278704 -> 138281255522784
	138280657278704 [label=TBackward0]
	138280657284032 -> 138280657278704
	138280784723120 [label="fc.weight
 (1000, 512)" fillcolor=lightblue]
	138280784723120 -> 138280657284032
	138280657284032 [label=AccumulateGrad]
	138281255522784 -> 138280652518224
}
