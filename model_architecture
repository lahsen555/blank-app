digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	138280652639888 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	138280788524288 [label=AddmmBackward0]
	138280788523136 -> 138280788524288
	138280784723216 [label="fc.bias
 (1000)" fillcolor=lightblue]
	138280784723216 -> 138280788523136
	138280788523136 [label=AccumulateGrad]
	138280788523520 -> 138280788524288
	138280788523520 [label=ViewBackward0]
	138280784533568 -> 138280788523520
	138280784533568 [label=MeanBackward1]
	138280784530736 -> 138280784533568
	138280784530736 [label=ReluBackward0]
	138280784531072 -> 138280784530736
	138280784531072 [label=AddBackward0]
	138280784535488 -> 138280784531072
	138280784535488 [label=NativeBatchNormBackward0]
	138284788879696 -> 138280784535488
	138284788879696 [label=ConvolutionBackward0]
	138284788880608 -> 138284788879696
	138284788880608 [label=ReluBackward0]
	138280784925248 -> 138284788880608
	138280784925248 [label=NativeBatchNormBackward0]
	138280784924240 -> 138280784925248
	138280784924240 [label=ConvolutionBackward0]
	138280784528432 -> 138280784924240
	138280784528432 [label=ReluBackward0]
	138280784921552 -> 138280784528432
	138280784921552 [label=AddBackward0]
	138280784924816 -> 138280784921552
	138280784924816 [label=NativeBatchNormBackward0]
	138280784926976 -> 138280784924816
	138280784926976 [label=ConvolutionBackward0]
	138280784928464 -> 138280784926976
	138280784928464 [label=ReluBackward0]
	138280784928992 -> 138280784928464
	138280784928992 [label=NativeBatchNormBackward0]
	138280784929472 -> 138280784928992
	138280784929472 [label=ConvolutionBackward0]
	138280784931008 -> 138280784929472
	138280784931008 [label=ReluBackward0]
	138280784932784 -> 138280784931008
	138280784932784 [label=AddBackward0]
	138280784933264 -> 138280784932784
	138280784933264 [label=NativeBatchNormBackward0]
	138280784933792 -> 138280784933264
	138280784933792 [label=ConvolutionBackward0]
	138280784935280 -> 138280784933792
	138280784935280 [label=ReluBackward0]
	138280784920640 -> 138280784935280
	138280784920640 [label=NativeBatchNormBackward0]
	138280784921888 -> 138280784920640
	138280784921888 [label=ConvolutionBackward0]
	138280784932400 -> 138280784921888
	138280784932400 [label=ReluBackward0]
	138280784932304 -> 138280784932400
	138280784932304 [label=AddBackward0]
	138280784935616 -> 138280784932304
	138280784935616 [label=NativeBatchNormBackward0]
	138280784935664 -> 138280784935616
	138280784935664 [label=ConvolutionBackward0]
	138280784922032 -> 138280784935664
	138280784922032 [label=ReluBackward0]
	138280784924576 -> 138280784922032
	138280784924576 [label=NativeBatchNormBackward0]
	138280784923040 -> 138280784924576
	138280784923040 [label=ConvolutionBackward0]
	138280784924000 -> 138280784923040
	138280784924000 [label=ReluBackward0]
	138280784924288 -> 138280784924000
	138280784924288 [label=AddBackward0]
	138280784924624 -> 138280784924288
	138280784924624 [label=NativeBatchNormBackward0]
	138280784924048 -> 138280784924624
	138280784924048 [label=ConvolutionBackward0]
	138280784923952 -> 138280784924048
	138280784923952 [label=ReluBackward0]
	138280784923856 -> 138280784923952
	138280784923856 [label=NativeBatchNormBackward0]
	138280784922992 -> 138280784923856
	138280784922992 [label=ConvolutionBackward0]
	138280784924192 -> 138280784922992
	138280784924192 [label=ReluBackward0]
	138280784922896 -> 138280784924192
	138280784922896 [label=AddBackward0]
	138280784922416 -> 138280784922896
	138280784922416 [label=NativeBatchNormBackward0]
	138280784921312 -> 138280784922416
	138280784921312 [label=ConvolutionBackward0]
	138280784921360 -> 138280784921312
	138280784921360 [label=ReluBackward0]
	138280784920688 -> 138280784921360
	138280784920688 [label=NativeBatchNormBackward0]
	138280784920880 -> 138280784920688
	138280784920880 [label=ConvolutionBackward0]
	138280784924864 -> 138280784920880
	138280784924864 [label=ReluBackward0]
	138280784925680 -> 138280784924864
	138280784925680 [label=AddBackward0]
	138280784925728 -> 138280784925680
	138280784925728 [label=NativeBatchNormBackward0]
	138280784926064 -> 138280784925728
	138280784926064 [label=ConvolutionBackward0]
	138280784926352 -> 138280784926064
	138280784926352 [label=ReluBackward0]
	138280784926880 -> 138280784926352
	138280784926880 [label=NativeBatchNormBackward0]
	138280784926736 -> 138280784926880
	138280784926736 [label=ConvolutionBackward0]
	138280784924960 -> 138280784926736
	138280784924960 [label=ReluBackward0]
	138280784927360 -> 138280784924960
	138280784927360 [label=AddBackward0]
	138280784927648 -> 138280784927360
	138280784927648 [label=NativeBatchNormBackward0]
	138280784927600 -> 138280784927648
	138280784927600 [label=ConvolutionBackward0]
	138280784928176 -> 138280784927600
	138280784928176 [label=ReluBackward0]
	138280784928320 -> 138280784928176
	138280784928320 [label=NativeBatchNormBackward0]
	138280784928512 -> 138280784928320
	138280784928512 [label=ConvolutionBackward0]
	138280784927264 -> 138280784928512
	138280784927264 [label=MaxPool2DWithIndicesBackward0]
	138280784929232 -> 138280784927264
	138280784929232 [label=ReluBackward0]
	138280784929520 -> 138280784929232
	138280784929520 [label=NativeBatchNormBackward0]
	138280784929376 -> 138280784929520
	138280784929376 [label=ConvolutionBackward0]
	138280784930144 -> 138280784929376
	138280784711600 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	138280784711600 -> 138280784930144
	138280784930144 [label=AccumulateGrad]
	138280784929184 -> 138280784929520
	138280784711696 [label="bn1.weight
 (64)" fillcolor=lightblue]
	138280784711696 -> 138280784929184
	138280784929184 [label=AccumulateGrad]
	138280784928896 -> 138280784929520
	138280784711792 [label="bn1.bias
 (64)" fillcolor=lightblue]
	138280784711792 -> 138280784928896
	138280784928896 [label=AccumulateGrad]
	138280784929040 -> 138280784928512
	138280784712176 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784712176 -> 138280784929040
	138280784929040 [label=AccumulateGrad]
	138280784928368 -> 138280784928320
	138280784712272 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	138280784712272 -> 138280784928368
	138280784928368 [label=AccumulateGrad]
	138280784928560 -> 138280784928320
	138280784712368 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	138280784712368 -> 138280784928560
	138280784928560 [label=AccumulateGrad]
	138280784928128 -> 138280784927600
	138280784712752 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784712752 -> 138280784928128
	138280784928128 [label=AccumulateGrad]
	138280784927840 -> 138280784927648
	138280784712848 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	138280784712848 -> 138280784927840
	138280784927840 [label=AccumulateGrad]
	138280784927888 -> 138280784927648
	138280784712944 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	138280784712944 -> 138280784927888
	138280784927888 [label=AccumulateGrad]
	138280784927264 -> 138280784927360
	138280784927120 -> 138280784926736
	138280784713328 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784713328 -> 138280784927120
	138280784927120 [label=AccumulateGrad]
	138280784926784 -> 138280784926880
	138280784713424 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	138280784713424 -> 138280784926784
	138280784926784 [label=AccumulateGrad]
	138280784926208 -> 138280784926880
	138280784713520 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	138280784713520 -> 138280784926208
	138280784926208 [label=AccumulateGrad]
	138280784926304 -> 138280784926064
	138280784713904 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784713904 -> 138280784926304
	138280784926304 [label=AccumulateGrad]
	138280784925872 -> 138280784925728
	138280784714000 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	138280784714000 -> 138280784925872
	138280784925872 [label=AccumulateGrad]
	138280784925104 -> 138280784925728
	138280784714096 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	138280784714096 -> 138280784925104
	138280784925104 [label=AccumulateGrad]
	138280784924960 -> 138280784925680
	138280784925056 -> 138280784920880
	138280784715056 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	138280784715056 -> 138280784925056
	138280784925056 [label=AccumulateGrad]
	138280784921072 -> 138280784920688
	138280784715152 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	138280784715152 -> 138280784921072
	138280784921072 [label=AccumulateGrad]
	138280784920928 -> 138280784920688
	138280784715248 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	138280784715248 -> 138280784920928
	138280784920928 [label=AccumulateGrad]
	138280784921936 -> 138280784921312
	138280784715632 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784715632 -> 138280784921936
	138280784921936 [label=AccumulateGrad]
	138280784921840 -> 138280784922416
	138280784715728 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	138280784715728 -> 138280784921840
	138280784921840 [label=AccumulateGrad]
	138280784921648 -> 138280784922416
	138280784715824 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	138280784715824 -> 138280784921648
	138280784921648 [label=AccumulateGrad]
	138280784922272 -> 138280784922896
	138280784922272 [label=NativeBatchNormBackward0]
	138280784921168 -> 138280784922272
	138280784921168 [label=ConvolutionBackward0]
	138280784924864 -> 138280784921168
	138280784925200 -> 138280784921168
	138280784714480 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	138280784714480 -> 138280784925200
	138280784925200 [label=AccumulateGrad]
	138280784921696 -> 138280784922272
	138280784714576 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	138280784714576 -> 138280784921696
	138280784921696 [label=AccumulateGrad]
	138280784921792 -> 138280784922272
	138280784714672 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	138280784714672 -> 138280784921792
	138280784921792 [label=AccumulateGrad]
	138280784923136 -> 138280784922992
	138280784716208 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784716208 -> 138280784923136
	138280784923136 [label=AccumulateGrad]
	138280784923088 -> 138280784923856
	138280784716304 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	138280784716304 -> 138280784923088
	138280784923088 [label=AccumulateGrad]
	138280784923760 -> 138280784923856
	138280784716400 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	138280784716400 -> 138280784923760
	138280784923760 [label=AccumulateGrad]
	138280784923328 -> 138280784924048
	138280784716784 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784716784 -> 138280784923328
	138280784923328 [label=AccumulateGrad]
	138280784924432 -> 138280784924624
	138280784716880 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	138280784716880 -> 138280784924432
	138280784924432 [label=AccumulateGrad]
	138280784924336 -> 138280784924624
	138280784716976 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	138280784716976 -> 138280784924336
	138280784924336 [label=AccumulateGrad]
	138280784924192 -> 138280784924288
	138280784921600 -> 138280784923040
	138280784717936 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	138280784717936 -> 138280784921600
	138280784921600 [label=AccumulateGrad]
	138280784924144 -> 138280784924576
	138280784717840 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	138280784717840 -> 138280784924144
	138280784924144 [label=AccumulateGrad]
	138280784921744 -> 138280784924576
	138280784718128 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	138280784718128 -> 138280784921744
	138280784921744 [label=AccumulateGrad]
	138280784923808 -> 138280784935664
	138280784718512 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784718512 -> 138280784923808
	138280784923808 [label=AccumulateGrad]
	138280784934080 -> 138280784935616
	138280784718608 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	138280784718608 -> 138280784934080
	138280784934080 [label=AccumulateGrad]
	138280784934416 -> 138280784935616
	138280784718704 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	138280784718704 -> 138280784934416
	138280784934416 [label=AccumulateGrad]
	138280784931920 -> 138280784932304
	138280784931920 [label=NativeBatchNormBackward0]
	138280784923664 -> 138280784931920
	138280784923664 [label=ConvolutionBackward0]
	138280784924000 -> 138280784923664
	138280784922560 -> 138280784923664
	138280784717360 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	138280784717360 -> 138280784922560
	138280784922560 [label=AccumulateGrad]
	138280784929856 -> 138280784931920
	138280784717456 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	138280784717456 -> 138280784929856
	138280784929856 [label=AccumulateGrad]
	138280784928272 -> 138280784931920
	138280784717552 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	138280784717552 -> 138280784928272
	138280784928272 [label=AccumulateGrad]
	138280784929808 -> 138280784921888
	138280784719088 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784719088 -> 138280784929808
	138280784929808 [label=AccumulateGrad]
	138280784936816 -> 138280784920640
	138280784719184 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	138280784719184 -> 138280784936816
	138280784936816 [label=AccumulateGrad]
	138280784936288 -> 138280784920640
	138280784719280 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	138280784719280 -> 138280784936288
	138280784936288 [label=AccumulateGrad]
	138280784935520 -> 138280784933792
	138280784719664 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784719664 -> 138280784935520
	138280784935520 [label=AccumulateGrad]
	138280784934272 -> 138280784933264
	138280784719760 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	138280784719760 -> 138280784934272
	138280784934272 [label=AccumulateGrad]
	138280784933312 -> 138280784933264
	138280784719856 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	138280784719856 -> 138280784933312
	138280784933312 [label=AccumulateGrad]
	138280784932400 -> 138280784932784
	138280784930960 -> 138280784929472
	138280784720816 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	138280784720816 -> 138280784930960
	138280784930960 [label=AccumulateGrad]
	138280784929712 -> 138280784928992
	138280784720912 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	138280784720912 -> 138280784929712
	138280784929712 [label=AccumulateGrad]
	138280784927984 -> 138280784928992
	138280784721008 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	138280784721008 -> 138280784927984
	138280784927984 [label=AccumulateGrad]
	138280784927504 -> 138280784926976
	138280784721392 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784721392 -> 138280784927504
	138280784927504 [label=AccumulateGrad]
	138280784925824 -> 138280784924816
	138280784721488 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	138280784721488 -> 138280784925824
	138280784925824 [label=AccumulateGrad]
	138280784926016 -> 138280784924816
	138280784721584 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	138280784721584 -> 138280784926016
	138280784926016 [label=AccumulateGrad]
	138280784924672 -> 138280784921552
	138280784924672 [label=NativeBatchNormBackward0]
	138280784930240 -> 138280784924672
	138280784930240 [label=ConvolutionBackward0]
	138280784931008 -> 138280784930240
	138280784931872 -> 138280784930240
	138280784720240 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	138280784720240 -> 138280784931872
	138280784931872 [label=AccumulateGrad]
	138280784927456 -> 138280784924672
	138280784720336 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	138280784720336 -> 138280784927456
	138280784927456 [label=AccumulateGrad]
	138280784926592 -> 138280784924672
	138280784720432 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	138280784720432 -> 138280784926592
	138280784926592 [label=AccumulateGrad]
	138280784922512 -> 138280784924240
	138280784721968 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784721968 -> 138280784922512
	138280784922512 [label=AccumulateGrad]
	138280784923616 -> 138280784925248
	138280784722064 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	138280784722064 -> 138280784923616
	138280784923616 [label=AccumulateGrad]
	138280784921120 -> 138280784925248
	138280784722160 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	138280784722160 -> 138280784921120
	138280784921120 [label=AccumulateGrad]
	138284788878976 -> 138284788879696
	138280784722544 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784722544 -> 138284788878976
	138284788878976 [label=AccumulateGrad]
	138284788879552 -> 138280784535488
	138280784722640 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	138280784722640 -> 138284788879552
	138284788879552 [label=AccumulateGrad]
	138284788878880 -> 138280784535488
	138280784722736 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	138280784722736 -> 138284788878880
	138284788878880 [label=AccumulateGrad]
	138280784528432 -> 138280784531072
	138280788523472 -> 138280788524288
	138280788523472 [label=TBackward0]
	138280784535056 -> 138280788523472
	138280784723120 [label="fc.weight
 (1000, 512)" fillcolor=lightblue]
	138280784723120 -> 138280784535056
	138280784535056 [label=AccumulateGrad]
	138280788524288 -> 138280652639888
}
