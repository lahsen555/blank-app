digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	138280648172240 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	138280784532080 [label=AddmmBackward0]
	138280784528144 -> 138280784532080
	138280784723216 [label="fc.bias
 (1000)" fillcolor=lightblue]
	138280784723216 -> 138280784528144
	138280784528144 [label=AccumulateGrad]
	138280784532128 -> 138280784532080
	138280784532128 [label=ViewBackward0]
	138280784530928 -> 138280784532128
	138280784530928 [label=MeanBackward1]
	138280784533664 -> 138280784530928
	138280784533664 [label=ReluBackward0]
	138280784533712 -> 138280784533664
	138280784533712 [label=AddBackward0]
	138280784530640 -> 138280784533712
	138280784530640 [label=NativeBatchNormBackward0]
	138280784532608 -> 138280784530640
	138280784532608 [label=ConvolutionBackward0]
	138280657284032 -> 138280784532608
	138280657284032 [label=ReluBackward0]
	138280657287008 -> 138280657284032
	138280657287008 [label=NativeBatchNormBackward0]
	138280657284656 -> 138280657287008
	138280657284656 [label=ConvolutionBackward0]
	138280784533616 -> 138280657284656
	138280784533616 [label=ReluBackward0]
	138280657274144 -> 138280784533616
	138280657274144 [label=AddBackward0]
	138280657279280 -> 138280657274144
	138280657279280 [label=NativeBatchNormBackward0]
	138280657276544 -> 138280657279280
	138280657276544 [label=ConvolutionBackward0]
	138280657285136 -> 138280657276544
	138280657285136 [label=ReluBackward0]
	138280657287488 -> 138280657285136
	138280657287488 [label=NativeBatchNormBackward0]
	138280657277456 -> 138280657287488
	138280657277456 [label=ConvolutionBackward0]
	138280657277360 -> 138280657277456
	138280657277360 [label=ReluBackward0]
	138280657287344 -> 138280657277360
	138280657287344 [label=AddBackward0]
	138280657276256 -> 138280657287344
	138280657276256 [label=NativeBatchNormBackward0]
	138280657278080 -> 138280657276256
	138280657278080 [label=ConvolutionBackward0]
	138280657283072 -> 138280657278080
	138280657283072 [label=ReluBackward0]
	138280657281200 -> 138280657283072
	138280657281200 [label=NativeBatchNormBackward0]
	138280657280048 -> 138280657281200
	138280657280048 [label=ConvolutionBackward0]
	138280657279904 -> 138280657280048
	138280657279904 [label=ReluBackward0]
	138280657275248 -> 138280657279904
	138280657275248 [label=AddBackward0]
	138280657287824 -> 138280657275248
	138280657287824 [label=NativeBatchNormBackward0]
	138280657279856 -> 138280657287824
	138280657279856 [label=ConvolutionBackward0]
	138280657287584 -> 138280657279856
	138280657287584 [label=ReluBackward0]
	138280657285760 -> 138280657287584
	138280657285760 [label=NativeBatchNormBackward0]
	138280657279328 -> 138280657285760
	138280657279328 [label=ConvolutionBackward0]
	138280657285904 -> 138280657279328
	138280657285904 [label=ReluBackward0]
	138280657286624 -> 138280657285904
	138280657286624 [label=AddBackward0]
	138280657283600 -> 138280657286624
	138280657283600 [label=NativeBatchNormBackward0]
	138280657278704 -> 138280657283600
	138280657278704 [label=ConvolutionBackward0]
	138280657283888 -> 138280657278704
	138280657283888 [label=ReluBackward0]
	138280657285184 -> 138280657283888
	138280657285184 [label=NativeBatchNormBackward0]
	138280657284080 -> 138280657285184
	138280657284080 [label=ConvolutionBackward0]
	138280657277696 -> 138280657284080
	138280657277696 [label=ReluBackward0]
	138280657284272 -> 138280657277696
	138280657284272 [label=AddBackward0]
	138280657284896 -> 138280657284272
	138280657284896 [label=NativeBatchNormBackward0]
	138280657284416 -> 138280657284896
	138280657284416 [label=ConvolutionBackward0]
	138280657288784 -> 138280657284416
	138280657288784 [label=ReluBackward0]
	138280657276784 -> 138280657288784
	138280657276784 [label=NativeBatchNormBackward0]
	138280657281872 -> 138280657276784
	138280657281872 [label=ConvolutionBackward0]
	138280657288304 -> 138280657281872
	138280657288304 [label=ReluBackward0]
	138280657288688 -> 138280657288304
	138280657288688 [label=AddBackward0]
	138280657273424 -> 138280657288688
	138280657273424 [label=NativeBatchNormBackward0]
	138280657274672 -> 138280657273424
	138280657274672 [label=ConvolutionBackward0]
	138280657276928 -> 138280657274672
	138280657276928 [label=ReluBackward0]
	138280657273760 -> 138280657276928
	138280657273760 [label=NativeBatchNormBackward0]
	138280657280672 -> 138280657273760
	138280657280672 [label=ConvolutionBackward0]
	138280657279472 -> 138280657280672
	138280657279472 [label=ReluBackward0]
	138280657272896 -> 138280657279472
	138280657272896 [label=AddBackward0]
	138280657274480 -> 138280657272896
	138280657274480 [label=NativeBatchNormBackward0]
	138280657273088 -> 138280657274480
	138280657273088 [label=ConvolutionBackward0]
	138280657274576 -> 138280657273088
	138280657274576 [label=ReluBackward0]
	138280657275344 -> 138280657274576
	138280657275344 [label=NativeBatchNormBackward0]
	138280657276880 -> 138280657275344
	138280657276880 [label=ConvolutionBackward0]
	138280657289024 -> 138280657276880
	138280657289024 [label=MaxPool2DWithIndicesBackward0]
	138280657273184 -> 138280657289024
	138280657273184 [label=ReluBackward0]
	138280657285520 -> 138280657273184
	138280657285520 [label=NativeBatchNormBackward0]
	138280657278656 -> 138280657285520
	138280657278656 [label=ConvolutionBackward0]
	138280657285856 -> 138280657278656
	138280784711600 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	138280784711600 -> 138280657285856
	138280657285856 [label=AccumulateGrad]
	138280657285664 -> 138280657285520
	138280784711696 [label="bn1.weight
 (64)" fillcolor=lightblue]
	138280784711696 -> 138280657285664
	138280657285664 [label=AccumulateGrad]
	138280657276064 -> 138280657285520
	138280784711792 [label="bn1.bias
 (64)" fillcolor=lightblue]
	138280784711792 -> 138280657276064
	138280657276064 [label=AccumulateGrad]
	138280657281776 -> 138280657276880
	138280784712176 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784712176 -> 138280657281776
	138280657281776 [label=AccumulateGrad]
	138280657279712 -> 138280657275344
	138280784712272 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	138280784712272 -> 138280657279712
	138280657279712 [label=AccumulateGrad]
	138280657283216 -> 138280657275344
	138280784712368 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	138280784712368 -> 138280657283216
	138280657283216 [label=AccumulateGrad]
	138280657288640 -> 138280657273088
	138280784712752 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784712752 -> 138280657288640
	138280657288640 [label=AccumulateGrad]
	138280657279616 -> 138280657274480
	138280784712848 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	138280784712848 -> 138280657279616
	138280657279616 [label=AccumulateGrad]
	138280657274432 -> 138280657274480
	138280784712944 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	138280784712944 -> 138280657274432
	138280657274432 [label=AccumulateGrad]
	138280657289024 -> 138280657272896
	138280657286048 -> 138280657280672
	138280784713328 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784713328 -> 138280657286048
	138280657286048 [label=AccumulateGrad]
	138280657277552 -> 138280657273760
	138280784713424 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	138280784713424 -> 138280657277552
	138280657277552 [label=AccumulateGrad]
	138280657284224 -> 138280657273760
	138280784713520 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	138280784713520 -> 138280657284224
	138280657284224 [label=AccumulateGrad]
	138280657278368 -> 138280657274672
	138280784713904 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784713904 -> 138280657278368
	138280657278368 [label=AccumulateGrad]
	138280657286000 -> 138280657273424
	138280784714000 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	138280784714000 -> 138280657286000
	138280657286000 [label=AccumulateGrad]
	138280657275824 -> 138280657273424
	138280784714096 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	138280784714096 -> 138280657275824
	138280657275824 [label=AccumulateGrad]
	138280657279472 -> 138280657288688
	138280657280384 -> 138280657281872
	138280784715056 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	138280784715056 -> 138280657280384
	138280657280384 [label=AccumulateGrad]
	138280657288496 -> 138280657276784
	138280784715152 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	138280784715152 -> 138280657288496
	138280657288496 [label=AccumulateGrad]
	138280657280240 -> 138280657276784
	138280784715248 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	138280784715248 -> 138280657280240
	138280657280240 [label=AccumulateGrad]
	138280657288448 -> 138280657284416
	138280784715632 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784715632 -> 138280657288448
	138280657288448 [label=AccumulateGrad]
	138280657276688 -> 138280657284896
	138280784715728 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	138280784715728 -> 138280657276688
	138280657276688 [label=AccumulateGrad]
	138280657284464 -> 138280657284896
	138280784715824 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	138280784715824 -> 138280657284464
	138280657284464 [label=AccumulateGrad]
	138280657275056 -> 138280657284272
	138280657275056 [label=NativeBatchNormBackward0]
	138280657280288 -> 138280657275056
	138280657280288 [label=ConvolutionBackward0]
	138280657288304 -> 138280657280288
	138280657288064 -> 138280657280288
	138280784714480 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	138280784714480 -> 138280657288064
	138280657288064 [label=AccumulateGrad]
	138280657279376 -> 138280657275056
	138280784714576 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	138280784714576 -> 138280657279376
	138280657279376 [label=AccumulateGrad]
	138280657288256 -> 138280657275056
	138280784714672 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	138280784714672 -> 138280657288256
	138280657288256 [label=AccumulateGrad]
	138280657285040 -> 138280657284080
	138280784716208 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784716208 -> 138280657285040
	138280657285040 [label=AccumulateGrad]
	138280657284176 -> 138280657285184
	138280784716304 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	138280784716304 -> 138280657284176
	138280657284176 [label=AccumulateGrad]
	138280657277312 -> 138280657285184
	138280784716400 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	138280784716400 -> 138280657277312
	138280657277312 [label=AccumulateGrad]
	138280657278176 -> 138280657278704
	138280784716784 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784716784 -> 138280657278176
	138280657278176 [label=AccumulateGrad]
	138280657283504 -> 138280657283600
	138280784716880 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	138280784716880 -> 138280657283504
	138280657283504 [label=AccumulateGrad]
	138280657282832 -> 138280657283600
	138280784716976 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	138280784716976 -> 138280657282832
	138280657282832 [label=AccumulateGrad]
	138280657277696 -> 138280657286624
	138280657286528 -> 138280657279328
	138280784717936 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	138280784717936 -> 138280657286528
	138280657286528 [label=AccumulateGrad]
	138280657279232 -> 138280657285760
	138280784717840 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	138280784717840 -> 138280657279232
	138280657279232 [label=AccumulateGrad]
	138280657278944 -> 138280657285760
	138280784718128 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	138280784718128 -> 138280657278944
	138280657278944 [label=AccumulateGrad]
	138280657282016 -> 138280657279856
	138280784718512 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784718512 -> 138280657282016
	138280657282016 [label=AccumulateGrad]
	138280657279808 -> 138280657287824
	138280784718608 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	138280784718608 -> 138280657279808
	138280657279808 [label=AccumulateGrad]
	138280657279664 -> 138280657287824
	138280784718704 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	138280784718704 -> 138280657279664
	138280657279664 [label=AccumulateGrad]
	138280657279952 -> 138280657275248
	138280657279952 [label=NativeBatchNormBackward0]
	138280657287248 -> 138280657279952
	138280657287248 [label=ConvolutionBackward0]
	138280657285904 -> 138280657287248
	138280657286336 -> 138280657287248
	138280784717360 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	138280784717360 -> 138280657286336
	138280657286336 [label=AccumulateGrad]
	138280657279424 -> 138280657279952
	138280784717456 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	138280784717456 -> 138280657279424
	138280657279424 [label=AccumulateGrad]
	138280657287776 -> 138280657279952
	138280784717552 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	138280784717552 -> 138280657287776
	138280657287776 [label=AccumulateGrad]
	138280657282496 -> 138280657280048
	138280784719088 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784719088 -> 138280657282496
	138280657282496 [label=AccumulateGrad]
	138280657273616 -> 138280657281200
	138280784719184 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	138280784719184 -> 138280657273616
	138280657273616 [label=AccumulateGrad]
	138280657277408 -> 138280657281200
	138280784719280 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	138280784719280 -> 138280657277408
	138280657277408 [label=AccumulateGrad]
	138280657286960 -> 138280657278080
	138280784719664 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784719664 -> 138280657286960
	138280657286960 [label=AccumulateGrad]
	138280657277024 -> 138280657276256
	138280784719760 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	138280784719760 -> 138280657277024
	138280657277024 [label=AccumulateGrad]
	138280657273376 -> 138280657276256
	138280784719856 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	138280784719856 -> 138280657273376
	138280657273376 [label=AccumulateGrad]
	138280657279904 -> 138280657287344
	138280657284848 -> 138280657277456
	138280784720816 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	138280784720816 -> 138280657284848
	138280657284848 [label=AccumulateGrad]
	138280657285232 -> 138280657287488
	138280784720912 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	138280784720912 -> 138280657285232
	138280657285232 [label=AccumulateGrad]
	138280657276832 -> 138280657287488
	138280784721008 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	138280784721008 -> 138280657276832
	138280657276832 [label=AccumulateGrad]
	138280657280912 -> 138280657276544
	138280784721392 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784721392 -> 138280657280912
	138280657280912 [label=AccumulateGrad]
	138280657278848 -> 138280657279280
	138280784721488 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	138280784721488 -> 138280657278848
	138280657278848 [label=AccumulateGrad]
	138280657275776 -> 138280657279280
	138280784721584 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	138280784721584 -> 138280657275776
	138280657275776 [label=AccumulateGrad]
	138280657280528 -> 138280657274144
	138280657280528 [label=NativeBatchNormBackward0]
	138280657278320 -> 138280657280528
	138280657278320 [label=ConvolutionBackward0]
	138280657277360 -> 138280657278320
	138280657276448 -> 138280657278320
	138280784720240 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	138280784720240 -> 138280657276448
	138280657276448 [label=AccumulateGrad]
	138280657272992 -> 138280657280528
	138280784720336 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	138280784720336 -> 138280657272992
	138280657272992 [label=AccumulateGrad]
	138280657273904 -> 138280657280528
	138280784720432 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	138280784720432 -> 138280657273904
	138280657273904 [label=AccumulateGrad]
	138280657280720 -> 138280657284656
	138280784721968 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784721968 -> 138280657280720
	138280657280720 [label=AccumulateGrad]
	138280657276208 -> 138280657287008
	138280784722064 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	138280784722064 -> 138280657276208
	138280657276208 [label=AccumulateGrad]
	138280657285568 -> 138280657287008
	138280784722160 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	138280784722160 -> 138280657285568
	138280657285568 [label=AccumulateGrad]
	138280657287296 -> 138280784532608
	138280784722544 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784722544 -> 138280657287296
	138280657287296 [label=AccumulateGrad]
	138280657276112 -> 138280784530640
	138280784722640 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	138280784722640 -> 138280657276112
	138280657276112 [label=AccumulateGrad]
	138280657280000 -> 138280784530640
	138280784722736 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	138280784722736 -> 138280657280000
	138280657280000 [label=AccumulateGrad]
	138280784533616 -> 138280784533712
	138280784534000 -> 138280784532080
	138280784534000 [label=TBackward0]
	138280784534960 -> 138280784534000
	138280784723120 [label="fc.weight
 (1000, 512)" fillcolor=lightblue]
	138280784723120 -> 138280784534960
	138280784534960 [label=AccumulateGrad]
	138280784532080 -> 138280648172240
}
