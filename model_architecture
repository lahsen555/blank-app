digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	138280648378992 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	138284788879600 [label=AddmmBackward0]
	138284788879840 -> 138284788879600
	138280784723216 [label="fc.bias
 (1000)" fillcolor=lightblue]
	138280784723216 -> 138284788879840
	138284788879840 [label=AccumulateGrad]
	138284788880368 -> 138284788879600
	138284788880368 [label=ViewBackward0]
	138280788524432 -> 138284788880368
	138280788524432 [label=MeanBackward1]
	138280788523520 -> 138280788524432
	138280788523520 [label=ReluBackward0]
	138280788522992 -> 138280788523520
	138280788522992 [label=AddBackward0]
	138280788524096 -> 138280788522992
	138280788524096 [label=NativeBatchNormBackward0]
	138280784860096 -> 138280788524096
	138280784860096 [label=ConvolutionBackward0]
	138280784936048 -> 138280784860096
	138280784936048 [label=ReluBackward0]
	138280784931296 -> 138280784936048
	138280784931296 [label=NativeBatchNormBackward0]
	138280784932208 -> 138280784931296
	138280784932208 [label=ConvolutionBackward0]
	138280788523280 -> 138280784932208
	138280788523280 [label=ReluBackward0]
	138280784927312 -> 138280788523280
	138280784927312 [label=AddBackward0]
	138280784933984 -> 138280784927312
	138280784933984 [label=NativeBatchNormBackward0]
	138280784935040 -> 138280784933984
	138280784935040 [label=ConvolutionBackward0]
	138280784923712 -> 138280784935040
	138280784923712 [label=ReluBackward0]
	138280784935088 -> 138280784923712
	138280784935088 [label=NativeBatchNormBackward0]
	138280784924720 -> 138280784935088
	138280784924720 [label=ConvolutionBackward0]
	138280784929808 -> 138280784924720
	138280784929808 [label=ReluBackward0]
	138280784928896 -> 138280784929808
	138280784928896 [label=AddBackward0]
	138280784921360 -> 138280784928896
	138280784921360 [label=NativeBatchNormBackward0]
	138280784929040 -> 138280784921360
	138280784929040 [label=ConvolutionBackward0]
	138280784935856 -> 138280784929040
	138280784935856 [label=ReluBackward0]
	138280784930720 -> 138280784935856
	138280784930720 [label=NativeBatchNormBackward0]
	138280784930192 -> 138280784930720
	138280784930192 [label=ConvolutionBackward0]
	138280784927600 -> 138280784930192
	138280784927600 [label=ReluBackward0]
	138280784933264 -> 138280784927600
	138280784933264 [label=AddBackward0]
	138280784934416 -> 138280784933264
	138280784934416 [label=NativeBatchNormBackward0]
	138280784935424 -> 138280784934416
	138280784935424 [label=ConvolutionBackward0]
	138280784927120 -> 138280784935424
	138280784927120 [label=ReluBackward0]
	138280784936288 -> 138280784927120
	138280784936288 [label=NativeBatchNormBackward0]
	138280784925344 -> 138280784936288
	138280784925344 [label=ConvolutionBackward0]
	138280784922656 -> 138280784925344
	138280784922656 [label=ReluBackward0]
	138280784921264 -> 138280784922656
	138280784921264 [label=AddBackward0]
	138280784929760 -> 138280784921264
	138280784929760 [label=NativeBatchNormBackward0]
	138280784928656 -> 138280784929760
	138280784928656 [label=ConvolutionBackward0]
	138280784931200 -> 138280784928656
	138280784931200 [label=ReluBackward0]
	138280784931056 -> 138280784931200
	138280784931056 [label=NativeBatchNormBackward0]
	138280784931632 -> 138280784931056
	138280784931632 [label=ConvolutionBackward0]
	138280784926928 -> 138280784931632
	138280784926928 [label=ReluBackward0]
	138280784931680 -> 138280784926928
	138280784931680 [label=AddBackward0]
	138280784932112 -> 138280784931680
	138280784932112 [label=NativeBatchNormBackward0]
	138280784933168 -> 138280784932112
	138280784933168 [label=ConvolutionBackward0]
	138280784928704 -> 138280784933168
	138280784928704 [label=ReluBackward0]
	138280784927456 -> 138280784928704
	138280784927456 [label=NativeBatchNormBackward0]
	138280784935616 -> 138280784927456
	138280784935616 [label=ConvolutionBackward0]
	138280784928176 -> 138280784935616
	138280784928176 [label=ReluBackward0]
	138280784936192 -> 138280784928176
	138280784936192 [label=AddBackward0]
	138280784932736 -> 138280784936192
	138280784932736 [label=NativeBatchNormBackward0]
	138280784933216 -> 138280784932736
	138280784933216 [label=ConvolutionBackward0]
	138280784934464 -> 138280784933216
	138280784934464 [label=ReluBackward0]
	138280784933744 -> 138280784934464
	138280784933744 [label=NativeBatchNormBackward0]
	138280784933936 -> 138280784933744
	138280784933936 [label=ConvolutionBackward0]
	138280784929616 -> 138280784933936
	138280784929616 [label=ReluBackward0]
	138280784934896 -> 138280784929616
	138280784934896 [label=AddBackward0]
	138280784935184 -> 138280784934896
	138280784935184 [label=NativeBatchNormBackward0]
	138280784923520 -> 138280784935184
	138280784923520 [label=ConvolutionBackward0]
	138280784936768 -> 138280784923520
	138280784936768 [label=ReluBackward0]
	138280784922128 -> 138280784936768
	138280784922128 [label=NativeBatchNormBackward0]
	138280784927024 -> 138280784922128
	138280784927024 [label=ConvolutionBackward0]
	138280784935760 -> 138280784927024
	138280784935760 [label=MaxPool2DWithIndicesBackward0]
	138280784927696 -> 138280784935760
	138280784927696 [label=ReluBackward0]
	138280784932976 -> 138280784927696
	138280784932976 [label=NativeBatchNormBackward0]
	138280784929136 -> 138280784932976
	138280784929136 [label=ConvolutionBackward0]
	138280784933504 -> 138280784929136
	138280784711600 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	138280784711600 -> 138280784933504
	138280784933504 [label=AccumulateGrad]
	138280784933888 -> 138280784932976
	138280784711696 [label="bn1.weight
 (64)" fillcolor=lightblue]
	138280784711696 -> 138280784933888
	138280784933888 [label=AccumulateGrad]
	138280784921408 -> 138280784932976
	138280784711792 [label="bn1.bias
 (64)" fillcolor=lightblue]
	138280784711792 -> 138280784921408
	138280784921408 [label=AccumulateGrad]
	138280784921456 -> 138280784927024
	138280784712176 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784712176 -> 138280784921456
	138280784921456 [label=AccumulateGrad]
	138280784924768 -> 138280784922128
	138280784712272 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	138280784712272 -> 138280784924768
	138280784924768 [label=AccumulateGrad]
	138280784936864 -> 138280784922128
	138280784712368 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	138280784712368 -> 138280784936864
	138280784936864 [label=AccumulateGrad]
	138280784936432 -> 138280784923520
	138280784712752 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784712752 -> 138280784936432
	138280784936432 [label=AccumulateGrad]
	138280784936096 -> 138280784935184
	138280784712848 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	138280784712848 -> 138280784936096
	138280784936096 [label=AccumulateGrad]
	138280784935952 -> 138280784935184
	138280784712944 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	138280784712944 -> 138280784935952
	138280784935952 [label=AccumulateGrad]
	138280784935760 -> 138280784934896
	138280784935568 -> 138280784933936
	138280784713328 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784713328 -> 138280784935568
	138280784935568 [label=AccumulateGrad]
	138280784934368 -> 138280784933744
	138280784713424 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	138280784713424 -> 138280784934368
	138280784934368 [label=AccumulateGrad]
	138280784934176 -> 138280784933744
	138280784713520 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	138280784713520 -> 138280784934176
	138280784934176 [label=AccumulateGrad]
	138280784923280 -> 138280784933216
	138280784713904 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	138280784713904 -> 138280784923280
	138280784923280 [label=AccumulateGrad]
	138280784931584 -> 138280784932736
	138280784714000 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	138280784714000 -> 138280784931584
	138280784931584 [label=AccumulateGrad]
	138280784932352 -> 138280784932736
	138280784714096 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	138280784714096 -> 138280784932352
	138280784932352 [label=AccumulateGrad]
	138280784929616 -> 138280784936192
	138280784930960 -> 138280784935616
	138280784715056 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	138280784715056 -> 138280784930960
	138280784930960 [label=AccumulateGrad]
	138280784935664 -> 138280784927456
	138280784715152 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	138280784715152 -> 138280784935664
	138280784935664 [label=AccumulateGrad]
	138280784921792 -> 138280784927456
	138280784715248 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	138280784715248 -> 138280784921792
	138280784921792 [label=AccumulateGrad]
	138280784921312 -> 138280784933168
	138280784715632 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784715632 -> 138280784921312
	138280784921312 [label=AccumulateGrad]
	138280784932880 -> 138280784932112
	138280784715728 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	138280784715728 -> 138280784932880
	138280784932880 [label=AccumulateGrad]
	138280784932064 -> 138280784932112
	138280784715824 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	138280784715824 -> 138280784932064
	138280784932064 [label=AccumulateGrad]
	138280784931824 -> 138280784931680
	138280784931824 [label=NativeBatchNormBackward0]
	138280784925584 -> 138280784931824
	138280784925584 [label=ConvolutionBackward0]
	138280784928176 -> 138280784925584
	138280784927360 -> 138280784925584
	138280784714480 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	138280784714480 -> 138280784927360
	138280784927360 [label=AccumulateGrad]
	138280784933120 -> 138280784931824
	138280784714576 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	138280784714576 -> 138280784933120
	138280784933120 [label=AccumulateGrad]
	138280784926256 -> 138280784931824
	138280784714672 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	138280784714672 -> 138280784926256
	138280784926256 [label=AccumulateGrad]
	138280784932160 -> 138280784931632
	138280784716208 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784716208 -> 138280784932160
	138280784932160 [label=AccumulateGrad]
	138280784930768 -> 138280784931056
	138280784716304 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	138280784716304 -> 138280784930768
	138280784930768 [label=AccumulateGrad]
	138280784930432 -> 138280784931056
	138280784716400 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	138280784716400 -> 138280784930432
	138280784930432 [label=AccumulateGrad]
	138280784930528 -> 138280784928656
	138280784716784 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	138280784716784 -> 138280784930528
	138280784930528 [label=AccumulateGrad]
	138280784929952 -> 138280784929760
	138280784716880 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	138280784716880 -> 138280784929952
	138280784929952 [label=AccumulateGrad]
	138280784929424 -> 138280784929760
	138280784716976 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	138280784716976 -> 138280784929424
	138280784929424 [label=AccumulateGrad]
	138280784926928 -> 138280784921264
	138280784934752 -> 138280784925344
	138280784717936 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	138280784717936 -> 138280784934752
	138280784934752 [label=AccumulateGrad]
	138280784928944 -> 138280784936288
	138280784717840 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	138280784717840 -> 138280784928944
	138280784928944 [label=AccumulateGrad]
	138280784927840 -> 138280784936288
	138280784718128 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	138280784718128 -> 138280784927840
	138280784927840 [label=AccumulateGrad]
	138280784926976 -> 138280784935424
	138280784718512 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784718512 -> 138280784926976
	138280784926976 [label=AccumulateGrad]
	138280784922080 -> 138280784934416
	138280784718608 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	138280784718608 -> 138280784922080
	138280784922080 [label=AccumulateGrad]
	138280784926544 -> 138280784934416
	138280784718704 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	138280784718704 -> 138280784926544
	138280784926544 [label=AccumulateGrad]
	138280784926208 -> 138280784933264
	138280784926208 [label=NativeBatchNormBackward0]
	138280784927072 -> 138280784926208
	138280784927072 [label=ConvolutionBackward0]
	138280784922656 -> 138280784927072
	138280784923184 -> 138280784927072
	138280784717360 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	138280784717360 -> 138280784923184
	138280784923184 [label=AccumulateGrad]
	138280784927504 -> 138280784926208
	138280784717456 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	138280784717456 -> 138280784927504
	138280784927504 [label=AccumulateGrad]
	138280784928128 -> 138280784926208
	138280784717552 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	138280784717552 -> 138280784928128
	138280784928128 [label=AccumulateGrad]
	138280784924192 -> 138280784930192
	138280784719088 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784719088 -> 138280784924192
	138280784924192 [label=AccumulateGrad]
	138280784922800 -> 138280784930720
	138280784719184 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	138280784719184 -> 138280784922800
	138280784922800 [label=AccumulateGrad]
	138280784934224 -> 138280784930720
	138280784719280 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	138280784719280 -> 138280784934224
	138280784934224 [label=AccumulateGrad]
	138280784929568 -> 138280784929040
	138280784719664 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	138280784719664 -> 138280784929568
	138280784929568 [label=AccumulateGrad]
	138280784924432 -> 138280784921360
	138280784719760 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	138280784719760 -> 138280784924432
	138280784924432 [label=AccumulateGrad]
	138280784931008 -> 138280784921360
	138280784719856 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	138280784719856 -> 138280784931008
	138280784931008 [label=AccumulateGrad]
	138280784927600 -> 138280784928896
	138280784922416 -> 138280784924720
	138280784720816 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	138280784720816 -> 138280784922416
	138280784922416 [label=AccumulateGrad]
	138280784931776 -> 138280784935088
	138280784720912 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	138280784720912 -> 138280784931776
	138280784931776 [label=AccumulateGrad]
	138280784927168 -> 138280784935088
	138280784721008 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	138280784721008 -> 138280784927168
	138280784927168 [label=AccumulateGrad]
	138280784925488 -> 138280784935040
	138280784721392 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784721392 -> 138280784925488
	138280784925488 [label=AccumulateGrad]
	138280784935232 -> 138280784933984
	138280784721488 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	138280784721488 -> 138280784935232
	138280784935232 [label=AccumulateGrad]
	138280784933696 -> 138280784933984
	138280784721584 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	138280784721584 -> 138280784933696
	138280784933696 [label=AccumulateGrad]
	138280784925392 -> 138280784927312
	138280784925392 [label=NativeBatchNormBackward0]
	138280784921600 -> 138280784925392
	138280784921600 [label=ConvolutionBackward0]
	138280784929808 -> 138280784921600
	138280784923136 -> 138280784921600
	138280784720240 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	138280784720240 -> 138280784923136
	138280784923136 [label=AccumulateGrad]
	138280784935808 -> 138280784925392
	138280784720336 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	138280784720336 -> 138280784935808
	138280784935808 [label=AccumulateGrad]
	138280784936624 -> 138280784925392
	138280784720432 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	138280784720432 -> 138280784936624
	138280784936624 [label=AccumulateGrad]
	138280784931920 -> 138280784932208
	138280784721968 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784721968 -> 138280784931920
	138280784931920 [label=AccumulateGrad]
	138280784930576 -> 138280784931296
	138280784722064 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	138280784722064 -> 138280784930576
	138280784930576 [label=AccumulateGrad]
	138280784928416 -> 138280784931296
	138280784722160 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	138280784722160 -> 138280784928416
	138280784928416 [label=AccumulateGrad]
	138280784930480 -> 138280784860096
	138280784722544 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	138280784722544 -> 138280784930480
	138280784930480 [label=AccumulateGrad]
	138280784865664 -> 138280788524096
	138280784722640 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	138280784722640 -> 138280784865664
	138280784865664 [label=AccumulateGrad]
	138280784869552 -> 138280788524096
	138280784722736 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	138280784722736 -> 138280784869552
	138280784869552 [label=AccumulateGrad]
	138280788523280 -> 138280788522992
	138284788879984 -> 138284788879600
	138284788879984 [label=TBackward0]
	138280788524144 -> 138284788879984
	138280784723120 [label="fc.weight
 (1000, 512)" fillcolor=lightblue]
	138280784723120 -> 138280788524144
	138280788524144 [label=AccumulateGrad]
	138284788879600 -> 138280648378992
}
